{#
 # This Source Code Form is subject to the terms of the Mozilla Public
 # License, v. 2.0. If a copy of the MPL was not distributed with this
 # file, You can obtain one at http://mozilla.org/MPL/2.0/.
 #}

{% extends "honorees-base.html" %}

{% block page_title %}Rise25 - 2024 Honorees - Meet the Change Agents{% endblock %}
{% block page_desc %}{% endblock %}

{% block body_class %}r25-t-orange{% endblock %}

{% block category_title %}Meet the Change Agents{% endblock %}
{% block category_desc %}
Challengers lead the way in diversifying AI, bringing varied community
voices into tech. They focus on inclusivity in AI development, ensuring
technology serves and represents everyone, especially those historically
excluded from the tech narrative. They are community leaders, corporate
leaders, activists and outside-the-box thinkers finding ways to amplify
the impacts of AI for marginalized communities. Their work fosters an
AI environment of equality and empowerment.
{% endblock %}

{% block honorees_content %}
{% call person(
    id='cansu-canca',
    name='Cansu<br> Canca',
    image='/media/img/people/placeholder.jpg'
  ) %}
    <p>Cansu is a philosopher and the Founder+Director of
      <a href="http://aiethicslab.com/" rel="noopener" target="_blank">AI Ethics Lab</a>,
      one of the first initiatives focusing exclusively on advising practitioners
      and conducting multidisciplinary research on AI ethics. She is also the
      Director of Responsible AI Practice at the
      <a href="https://ai.northeastern.edu/" rel="noopener" target="_blank">Institute for Experiential AI</a>
      and a Research Associate Professor in Philosophy at Northeastern
      University. With her team of computer scientists and philosophers, she
      provides hands-on, research based consulting in integrating ethics into
      AI innovation and implementing responsible AI strategy for organizations.</p>

    <p>Cansu has a Ph.D. in philosophy specializing in applied ethics. She
      serves as an ethics expert in various ethics, advisory, and editorial
      boards and to Fortune 500 companies. She works with
      <a href="https://initiatives.weforum.org/ai-governance-alliance/home">World Economic Forum</a>
      and with
      <a href="https://unicri.it/topics/Toolkit-Responsible-AI-for-Law-Enforcement-INTERPOL-UNICRI" rel="noopener" target="_blank">the UN and the INTERPOL</a>
      in developing guidelines for law enforcement, investors, and companies for
      responsible AI innovation.</p>

    <p>Cansu primarily works on ethics of technology, having previously worked
      extensively on ethics and health as a faculty member at the University of
      Hong Kong, and an ethics researcher at the Harvard Law School, Harvard
      School of Public Health, National University of Singapore, Osaka
      University, and the WHO.</p>
  {% endcall %}

  {% call person(
    id='angela-lungati',
    name='Angela<br> Lungati',
    image='/media/img/people/placeholder.jpg'
  ) %}
    <p>Angela is a technologist, community builder, and open-source software
      advocate passionate about building and using appropriate technology tools
      to impact the lives of marginalized groups. She has over ten years of
      experience in software development, global community engagement, and
      non-profit organizational management.</p>

    <p>She is the Executive Director at
      <a href="https://ushahidi.com/" rel="noopener" target="_blank">Ushahidi</a>,
      a global non-profit technology company that helps communities quickly
      collect and share information that enables them to raise voices, inform
      decisions and influence change.</p>

    <p>She sits on the Board of Directors for
      <a href="https://creativecommons.org/" rel="noopener" target="_blank">Creative Commons</a> and
      <a href="https://www.hotosm.org/" rel="noopener" target="_blank">Humanitarian OpenStreetMap Team</a>.
      She’s also a member of the
      <a href="https://www.weforum.org/" rel="noopener" target="_blank">World Economic Forum</a>’s
      <a href="https://www.weforum.org/communities/gfc-on-data-equity" rel="noopener" target="_blank">Global Futures Council on Data Equity</a>,
      and co-founder of
      <a href="https://akirachix.com/" rel="noopener" target="_blank">AkiraChix</a>, a
      non-profit organization that nurtures generations of women who use
      technology to develop innovations and solutions for Africa. She was also
      recently named a World Economic Forum
      <a href="https://www.younggloballeaders.org/new-class/" rel="noopener" target="_blank">Young Global Leader in 2024</a>.</p>
  {% endcall %}

  {% call person(
    id='elaine-nsoesie',
    name='Elaine<br> Nsoesie',
    image='/media/img/people/placeholder.jpg'
  ) %}
    <p>Elaine O. Nsoesie is an Associate Professor at Boston University School
      of Public Health. She uses data and technology to advance global health
      equity. She led the Racial Data Tracker project at Boston University’s
      Center for Antiracist Research which aimed to collect, analyze, and
      disseminate publicly available racial data that points to the structural
      nature of racism. She also served as a program lead and a senior advisor
      to the Artificial Intelligence/Machine Learning Consortium to Advance
      Health Equity and Researcher Diversity (AIM-AHEAD) program at the National
      Institutes of Health. She is the founder of Rethe – an initiative that
      aims to increase representation of Africans in scientific research
      publications. She is on the advisory boards of Data Science Africa and
      Data Scientists Network – organizations working to build data science
      capacity in Africa.</p>
  {% endcall %}

  {% call person(
    id='desmond-patton',
    name='Desmond<br> Patton',
    image='/media/img/people/placeholder.jpg'
  ) %}
    <ul>
      <li>Pioneering Social Scientist and Social Worker Whose Frameworks for
      Designing Ethical AI Ensure Well-Being for Diverse Communities and
      Organizational Cultures.</li>
      <li>Widely Cited Authority at the Intersection of Healthy Social Media
        Ecosystems, Empathy, Race and Society.</li>
      <li>Named a 2022 Top 50 in Digital Health, Equity Advocate.</li>
      <li>Penn Integrates Knowledge University Professor, University of
        Pennsylvania.</li>
      <li>Founding Director, SAFELab.</li>
      <li>Chief Strategy Officer, Penn School of Social Policy &amp;
        Practice.</li>
    </ul>
  {% endcall %}

  {% call person(
    id='divya-siddarth',
    name='Divya<br> Siddarth',
    image='/media/img/people/placeholder.jpg'
  ) %}
    <p>Divya Siddarth is the executive director and co-founder of the Collective
      Intelligence Project, which is developing and applying new governance
      models for artificial intelligence. She believes that transformative
      technologies will only advance the “public good” if we creatively involve
      the public, and that collective intelligence is a powerful tool for
      making AI better. To that end, Collective Intelligence has worked with
      partners such as the Taiwanese Digital Ministry, the UK AI Safety
      Institute, ITS Rio, OpenAI, Anthropic, and Creative Commons on designing
      “alignment assemblies” – early experiments in demonstrating how the broader
      public can effectively co-create and improve powerful AI models.</p>

    <p>Before founding CIP, Divya was Microsoft’s Office of the CTO’s political
      economist and social technologist. She graduated from Stanford with a B.S.
      in Computational Decision Analysis, and is pursuing a DPhil at the Oxford
      Internet Institute.</p>
  {% endcall %}

  <div class="r25-c-next r25-t-red">
    <a href="/advocates/">
      <h3>Meet the<br> Advocates</h3>
    </a>
  </div>
{% endblock %}
